# General
seed:-1
exp_name:full_context_string
debug:False

# Data
data_path:/work/rogupta/wikinet_data
data_type:proto
num_shards:100
train_size:1000000
query_size:5000
conll_split:dev
yamada_model:yamada_model.pickle
autoencoder_ckpt:/work/rogupta/wikinet_data/autoencoder/max_char_40_hidden_64.ckpt

# Gram Settings
gram_type:trigram
gram_lower:True
gram_dim:64

# Max padding
max_word_size:5
max_gram_size:35
max_context_size:100
max_char_size:40
max_ent_size:35

# Model types
init_emb:ckpt
emb_ckpt:/work/rogupta/wikinet_data/models/2018_11_10/pre_train_dim_128_epoch_50/best_model.ckpt
gensim_model:None
model_name:full_context_string

# Model Params
measure:ip
dp:0
mention_word_dim:128
ent_mention_dim:128
context_word_dim:128
combined_linear:True
init_stdv:0.001

# Normalization
norm_final:True

# Candidate Generation
cand_gen_rand:False
num_candidates:256

# Training Settings
patience:5
num_epochs:20
batch_size:32
num_workers:8
lr:1e-03
wd:1e-06
optim:adagrad
sparse:False
save_every:5

# Loss
margin:0.5
loss_func:cross_entropy

# Things to train
train_ent:True
train_word:True
train_mention:True
train_linear:True
train_gram:True

# Cuda
use_cuda:True
device:0
