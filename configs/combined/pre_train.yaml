# General
seed:-1
exp_name:pre_train
debug:False

# Data
data_path:/work/rogupta/wikinet_data
data_type:splits
num_shards:100
train_size:1000000
query_size:5000
conll_split:dev
yamada_model:yamada_model.pickle

# Gram Settings
gram_type:trigram
gram_lower:True
gram_dim:64

# Max padding
max_word_size:5
max_gram_size:35
max_context_size:100
max_ent_size:35

# Model types
init_emb:gensim
gensim_model:w2v-yamada-128-20-3
model_name:pre_train
init_stdv:0.001

# Model Params
measure:ip
dp:0
combined_linear:True
mention_word_dim:64
context_word_dim:128
ent_mention_dim:128

# Normalization
norm_gram:False
norm_word:False
norm_mention:False
norm_context:False
norm_final:True

# Candidate Generation
cand_gen_rand:True
num_candidates:256

# Training Settings
patience:5
num_epochs:20
batch_size:32
num_workers:8
lr:1e-03
wd:1e-06
optim:adagrad
sparse:False
save_every:5

# Loss
margin:0.5
loss_func:cross_entropy

# Things to train
train_ent:True
train_word:True
train_mention:True
train_linear:False
train_gram:True

# Cuda
use_cuda:True
device:0
